{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "predict-header",
            "metadata": {},
            "source": [
                "# **Customer Churn Prediction Notebook**\n",
                "This notebook demonstrates how to load the trained Random Forest model and make predictions on new customer data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "predict-imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import joblib\n",
                "import os\n",
                "\n",
                "# Define paths\n",
                "MODEL_PATH = '../models/rf_model.pkl'\n",
                "DATA_PATH = '../data/processed_churn_data.parquet'\n",
                "\n",
                "# Load the model\n",
                "if os.path.exists(MODEL_PATH):\n",
                "    model = joblib.load(MODEL_PATH)\n",
                "    print(\"Model loaded successfully!\")\n",
                "else:\n",
                "    print(f\"Error: Model not found at {MODEL_PATH}. Please run the training notebook first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "predict-demo-processed",
            "metadata": {},
            "source": [
                "## 1. Prediction using Prepared Data\n",
                "First, we'll demonstrate a prediction using the processed data generated in `preprocessing.ipynb`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "predict-demo-code",
            "metadata": {},
            "outputs": [],
            "source": [
                "if os.path.exists(DATA_PATH):\n",
                "    df = pd.read_parquet(DATA_PATH)\n",
                "    # Sample a row (excluding Churn)\n",
                "    sample_row = df.drop('Churn', axis=1).iloc[[0]]\n",
                "    actual_label = df.iloc[0]['Churn']\n",
                "    \n",
                "    prediction = model.predict(sample_row)[0]\n",
                "    probability = model.predict_proba(sample_row)[0][1]\n",
                "    \n",
                "    print(f\"Sample Customer Data (Processed):\")\n",
                "    display(sample_row)\n",
                "    print(f\"Actual Churn: {actual_label}\")\n",
                "    print(f\"Predicted Churn: {prediction}\")\n",
                "    print(f\"Churn Probability: {probability:.2%}\")\n",
                "else:\n",
                "    print(f\"Processed data file not found at {DATA_PATH}.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "predict-real-world",
            "metadata": {},
            "source": [
                "## 2. Prediction on Raw Data Sample\n",
                "In a real-world scenario, you will have raw customer data that needs to be encoded the same way as the training data. This section shows how to handle a raw sample."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "predict-raw-function",
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_raw_sample(raw_data, training_columns):\n",
                "    \"\"\"\n",
                "    Applies the encoding steps used in training to a single raw input sample.\n",
                "    \"\"\"\n",
                "    # 1. Create DataFrame\n",
                "    df_sample = pd.DataFrame([raw_data])\n",
                "    \n",
                "    # 2. Binary Encoding\n",
                "    binary_map = {'Yes': 1, 'No': 0}\n",
                "    binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling']\n",
                "    for col in binary_cols:\n",
                "        if col in df_sample.columns:\n",
                "            df_sample[col] = df_sample[col].replace(binary_map)\n",
                "    \n",
                "    if 'gender' in df_sample.columns:\n",
                "        df_sample['gender'] = df_sample['gender'].replace({'Female': 1, 'Male': 0})\n",
                "        \n",
                "    # 3. Handle TotalCharges numeric conversion\n",
                "    if 'TotalCharges' in df_sample.columns:\n",
                "        df_sample['TotalCharges'] = pd.to_numeric(df_sample['TotalCharges'], errors='coerce')\n",
                "    \n",
                "    # 4. One-Hot Encoding for multi-category columns\n",
                "    multi_cols = [\n",
                "        'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
                "        'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', \n",
                "        'Contract', 'PaymentMethod'\n",
                "    ]\n",
                "    \n",
                "    df_sample = pd.get_dummies(df_sample, columns=[c for c in multi_cols if c in df_sample.columns], dtype=int)\n",
                "    \n",
                "    # 5. Align columns with training data (adding missing dummies as 0)\n",
                "    for col in training_columns:\n",
                "        if col not in df_sample.columns:\n",
                "            df_sample[col] = 0\n",
                "            \n",
                "    # Ensure column order matches exactly\n",
                "    return df_sample[training_columns]\n",
                "\n",
                "# Example raw input (Missing Churn of course)\n",
                "raw_input = {\n",
                "    'gender': 'Female',\n",
                "    'SeniorCitizen': 0,\n",
                "    'Partner': 'Yes',\n",
                "    'Dependents': 'No',\n",
                "    'tenure': 1,\n",
                "    'PhoneService': 'No',\n",
                "    'MultipleLines': 'No phone service',\n",
                "    'InternetService': 'DSL',\n",
                "    'OnlineSecurity': 'No',\n",
                "    'OnlineBackup': 'Yes',\n",
                "    'DeviceProtection': 'No',\n",
                "    'TechSupport': 'No',\n",
                "    'StreamingTV': 'No',\n",
                "    'StreamingMovies': 'No',\n",
                "    'Contract': 'Month-to-month',\n",
                "    'PaperlessBilling': 'Yes',\n",
                "    'PaymentMethod': 'Electronic check',\n",
                "    'MonthlyCharges': 29.85,\n",
                "    'TotalCharges': \"29.85\"\n",
                "}\n",
                "\n",
                "# Get training columns from model\n",
                "training_features = model.feature_names_in_\n",
                "\n",
                "processed_sample = preprocess_raw_sample(raw_input, training_features)\n",
                "prediction = model.predict(processed_sample)[0]\n",
                "probability = model.predict_proba(processed_sample)[0][1]\n",
                "\n",
                "print(f\"Raw Input Sample Prediction Result:\")\n",
                "print(f\"Predicted Churn: {'Yes' if prediction == 1 else 'No'}\")\n",
                "print(f\"Confidence Probability: {probability:.2%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "app-integration-guide",
            "metadata": {},
            "source": [
                "## 3. App Integration Guide\n",
                "To use this logic in a web application (like Flask or Streamlit), you can follow these steps:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "app-integration-steps",
            "metadata": {},
            "source": [
                "### Step 1: Export the Logic\n",
                "You can save the `preprocess_raw_sample` function in a `.py` file (e.g., `utils.py`) so your app can import it.\n",
                "\n",
                "### Step 2: Sample Integration (Flask Example)\n",
                "```python\n",
                "from flask import Flask, request, jsonify\n",
                "import joblib\n",
                "import pandas as pd\n",
                "from utils import preprocess_raw_sample\n",
                "\n",
                "app = Flask(__name__)\n",
                "model = joblib.load('models/rf_model.pkl')\n",
                "training_features = model.feature_names_in_\n",
                "\n",
                "@app.route('/predict', methods=['POST'])\n",
                "def predict():\n",
                "    data = request.json  # Get raw JSON from frontend\n",
                "    processed_df = preprocess_raw_sample(data, training_features)\n",
                "    \n",
                "    prediction = model.predict(processed_df)[0]\n",
                "    probability = model.predict_proba(processed_df)[0][1]\n",
                "    \n",
                "    return jsonify({\n",
                "        'churn': bool(prediction),\n",
                "        'probability': float(probability)\n",
                "    })\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}